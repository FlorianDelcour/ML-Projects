{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_data(data_path):\n",
    "\n",
    "    FEATURES = range(2, 33)\n",
    "    N_TIME_SERIES = 3500\n",
    "\n",
    "    # Create the training and testing samples\n",
    "    LS_path = os.path.join(data_path, 'LS')\n",
    "    TS_path = os.path.join(data_path, 'TS')\n",
    "    X_train, X_test = [np.zeros((N_TIME_SERIES, (len(FEATURES) * 512))) for i in range(2)]\n",
    "\n",
    "    for f in FEATURES:\n",
    "        data = np.loadtxt(os.path.join(LS_path, 'LS_sensor_{}.txt'.format(f)))\n",
    "        X_train[:, (f-2)*512:(f-2+1)*512] = data\n",
    "        data = np.loadtxt(os.path.join(TS_path, 'TS_sensor_{}.txt'.format(f)))\n",
    "        X_test[:, (f-2)*512:(f-2+1)*512] = data\n",
    "    \n",
    "    y_train = np.loadtxt(os.path.join(LS_path, 'activity_Id.txt'))\n",
    "\n",
    "    print('X_train size: {}.'.format(X_train.shape))\n",
    "    print('y_train size: {}.'.format(y_train.shape))\n",
    "    print('X_test size: {}.'.format(X_test.shape))\n",
    "\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: (3500, 15872).\n",
      "y_train size: (3500,).\n",
      "X_test size: (3500, 15872).\n"
     ]
    }
   ],
   "source": [
    "X_train_raw, y_train_raw, X_test_raw = load_data('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4957990\n",
      "8.924953197004609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count missing values\n",
    "print(np.sum(X_train_raw == -999999.99))\n",
    "print(np.sum(X_train_raw == -999999.99)*100/(len(X_train_raw)*X_train_raw.shape[1]))\n",
    "np.sum(X_test_raw == -999999.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing(X_train, y_train):\n",
    "    \n",
    "    subject_1 = [[], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "    subject_2 = [[], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "    subject_3 = [[], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "    subject_4 = [[], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "    subject_5 = [[], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "    activities = [[], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "    sub_id = np.loadtxt(os.path.join('data', 'LS', 'subject_Id.txt'))\n",
    "    \n",
    "    for i in range(len(y_train)):\n",
    "        activities[int(y_train[i] - 1)].append(i)\n",
    "        if int(sub_id[i]) == 1:\n",
    "            subject_1[int(y_train[i] - 1)].append(i)\n",
    "        elif int(sub_id[i]) == 2:\n",
    "            subject_2[int(y_train[i] - 1)].append(i)\n",
    "        elif int(sub_id[i]) == 3:\n",
    "            subject_3[int(y_train[i] - 1)].append(i)\n",
    "        elif int(sub_id[i]) == 4:\n",
    "            subject_4[int(y_train[i] - 1)].append(i)\n",
    "        elif int(sub_id[i]) == 5:\n",
    "            subject_5[int(y_train[i] - 1)].append(i)\n",
    "\n",
    "    X_train[X_train == -999999.99] = np.nan\n",
    "\n",
    "    for subject in [subject_1, subject_2, subject_3, subject_4, subject_5]:\n",
    "        for activity in subject:\n",
    "            if activity:\n",
    "                data_mat = X_train[activity]\n",
    "                for i in range(len(data_mat[0])):\n",
    "                    if len(data_mat[:, i]) != len(data_mat[np.isnan(data_mat[:, i]), i]) and \\\n",
    "                            True in np.isnan(X_train[activity, i]):\n",
    "                        mean_col = np.nanmean(data_mat[:, i])\n",
    "                        index_nan = []\n",
    "                        isnan_X_train = np.isnan(X_train[activity, i])\n",
    "                        for k in range(len(isnan_X_train)):\n",
    "                            if isnan_X_train[k]:\n",
    "                                index_nan.append(activity[k])\n",
    "                        X_train[index_nan, i] = mean_col\n",
    "\n",
    "    for i in range(len(X_train[0])):\n",
    "        for activity in activities:\n",
    "            if True in np.isnan(X_train[activity, i]):\n",
    "                index_nan = []\n",
    "                isnan_X_train = np.isnan(X_train[activity, i])\n",
    "                for k in range(len(isnan_X_train)):\n",
    "                    if isnan_X_train[k]:\n",
    "                        index_nan.append(activity[k])\n",
    "                mean_activity = np.nanmean(X_train[activity, i])\n",
    "                X_train[index_nan, i] = mean_activity\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = missing(X_train_raw, y_train_raw) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-32091.38 -110348.95\n",
      "1713.45 1597.99\n"
     ]
    }
   ],
   "source": [
    "# min and max of X_train and X_test\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print(np.min(X_train), np.min(X_test_raw))\n",
    "print(np.max(X_train), np.max(X_test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-53.275\n",
      "177.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'ID activities')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Boxplot of the median per activities\n",
    "df_tot = pd.DataFrame(X_train)\n",
    "df_tot['id_activity'] = y_train_raw\n",
    "df_median = df_tot.groupby('id_activity').median()\n",
    "print(np.min(df_median.min()))\n",
    "print(np.max(df_median.max()))\n",
    "df_median = df_median.transpose()\n",
    "ax = df_median.boxplot(figsize=(14,10))\n",
    "ax.set_xlabel('ID activities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier(X):\n",
    "    n_rows = len(X)\n",
    "    for i in range(n_rows):\n",
    "        for j in range(31):\n",
    "            sensor_values = X[i, j*512:(j+1)*512]\n",
    "            sensor_values[sensor_values>200] = np.nan\n",
    "            sensor_values[sensor_values<-200] = np.nan\n",
    "            df = pd.DataFrame(sensor_values)\n",
    "            df = (df.bfill() + df.ffill()) / 2\n",
    "            if df.isnull().values.any():\n",
    "                df = df.bfill()\n",
    "            if df.isnull().values.any():\n",
    "                df = df.ffill()\n",
    "            sensor_values = df.to_numpy()[:,0]\n",
    "            X[i, j*512:(j+1)*512] = sensor_values\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = outlier(X_train)\n",
    "X_test = outlier(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, iqr\n",
    "\n",
    "def summarize(X):\n",
    "    h = len(X)\n",
    "    new_X = []\n",
    "    for i in range(0,h):\n",
    "        row_values = []\n",
    "        for j in range(0,31):\n",
    "            sensor_values = X[i, j*512:(j+1)*512]\n",
    "            sensor_fft = np.abs(np.fft.fft(sensor_values))\n",
    "            sensor_fft[::-1].sort()\n",
    "            sensor_fft = sensor_fft[:3]\n",
    "            row_values.append(np.mean(sensor_values))\n",
    "            row_values.append(np.std(sensor_values))\n",
    "            row_values.append(np.median(sensor_values))\n",
    "            row_values.append(kurtosis(sensor_values))\n",
    "            row_values.append(iqr(sensor_values))\n",
    "\n",
    "            for fft_value in sensor_fft:\n",
    "                row_values.append(fft_value)\n",
    "\n",
    "        new_X.append(row_values)\n",
    "    return np.asarray(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sum = summarize(X_train)\n",
    "X_train_unscale = np.array(X_train_sum)\n",
    "X_test_sum = summarize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "power_scaler = PowerTransformer(method='yeo-johnson')\n",
    "X_train_power = power_scaler.fit_transform(X_train_sum)\n",
    "X_test_power = power_scaler.fit_transform(X_test_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation - Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "def last(arr, low, high, x, n) :\n",
    "# reference : https://www.geeksforgeeks.org/find-first-and-last-positions-of-an-element-in-a-sorted-array/\n",
    "    if (high >= low) :\n",
    "        mid = low + (high - low) // 2\n",
    "        if (( mid == n - 1 or x < arr[mid + 1]) and arr[mid] == x) :\n",
    "            return mid\n",
    "        elif (x < arr[mid]) :\n",
    "            return last(arr, low, (mid - 1), x, n)\n",
    "        else :\n",
    "            return last(arr, (mid + 1), high, x, n)      \n",
    "    return -1\n",
    "\n",
    "def local_test(X_train, y_train):\n",
    "    # X_train and y_train will be sorted by the subject ID\n",
    "    subject_id = np.loadtxt(os.path.join('data', 'LS', 'subject_Id.txt'))\n",
    "    sort_by_subject = np.c_[subject_id, X_train]\n",
    "    sort_by_subject = np.c_[sort_by_subject, y_train]\n",
    "    sort_by_subject = sort_by_subject[sort_by_subject[:, 0].argsort()]\n",
    "    indices = [last(sort_by_subject[:,0], 0, len(sort_by_subject)-1, i, len(sort_by_subject)) + 1 for i in range(1,6)]\n",
    "    sort_by_subject = np.delete(sort_by_subject, 0, axis=1)\n",
    "    X_train = sort_by_subject[:, :sort_by_subject.shape[1]-1]\n",
    "    y_train = sort_by_subject[:, sort_by_subject.shape[1]-1]\n",
    "    return X_train, y_train, indices\n",
    "\n",
    "def loo_cv(m, X_trains, y_trains):\n",
    "    # Leave-One-Out Cross-Validation\n",
    "    scores = []\n",
    "\n",
    "    for i in range(0, 5):\n",
    "        X_LS = np.concatenate([X_trains[j] for j in range(0, 5) if j != i]) \n",
    "        y_LS = np.concatenate([y_trains[j] for j in range(0, 5) if j != i])\n",
    "\n",
    "        X_TS = X_trains_power[i]\n",
    "        y_TS = y_trains[i]\n",
    "\n",
    "        m.fit(X_LS, y_LS)\n",
    "        y_predicted = m.predict(X_TS)\n",
    "\n",
    "        score = accuracy_score(y_TS, y_predicted)\n",
    "        print(str(i) + \" out: \" + str(score))\n",
    "\n",
    "        #print(confusion_matrix(y_TS, y_predicted)) # Print confusion matrix can be useful to see the misclassifications\n",
    "        scores.append(score)\n",
    "\n",
    "    print(\"Mean score: \" + str(np.mean(scores)))\n",
    "    print(\"Std Dev score: \" + str(np.std(scores)))\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X_train_power by subject_id to perform the cross validation\n",
    "X_train, y_train, indices = local_test(X_train_power, y_train_raw)\n",
    "i1 = indices[0]\n",
    "i2 = indices[1]\n",
    "i3 = indices[2]\n",
    "i4 = indices[3] \n",
    "X_train1 = X_train[:i1, :]\n",
    "X_train2 = X_train[i1:i2, :]\n",
    "X_train3 = X_train[i2:i3, :]\n",
    "X_train4 = X_train[i3:i4, :]\n",
    "X_train5 = X_train[i4:, :]\n",
    "\n",
    "X_trains_power = [X_train1, X_train2, X_train3, X_train4, X_train5]\n",
    "\n",
    "y_train1 = y_train[:i1]\n",
    "y_train2 = y_train[i1:i2]\n",
    "y_train3 = y_train[i2:i3]\n",
    "y_train4 = y_train[i3:i4]\n",
    "y_train5 = y_train[i4:]\n",
    "\n",
    "y_trains = [y_train1, y_train2, y_train3, y_train4, y_train5]\n",
    "\n",
    "# Train set and test set to perform simple accuracy score (80% LS and 20% TS)\n",
    "X_train_LS = X_train[:i4, :]\n",
    "X_train_TS = X_train[i4:, :]\n",
    "y_train_LS = y_train[:i4]\n",
    "y_train_TS = y_train[i4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prove of poor efficiency on unscaled data for distance based algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unscale, _, indices = local_test(X_train_unscale, y_train_raw)\n",
    "i1 = indices[0]\n",
    "i2 = indices[1]\n",
    "i3 = indices[2]\n",
    "i4 = indices[3] \n",
    "X_train1_unscale = X_train_unscale[:i1, :]\n",
    "X_train2_unscale = X_train_unscale[i1:i2, :]\n",
    "X_train3_unscale = X_train_unscale[i2:i3, :]\n",
    "X_train4_unscale = X_train_unscale[i3:i4, :]\n",
    "X_train5_unscale = X_train_unscale[i4:, :]\n",
    "\n",
    "X_trains_unscale = [X_train1_unscale, X_train2_unscale, X_train3_unscale, X_train4_unscale, X_train5_unscale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled accuracy: 0.8988030467899891\n",
      "Unscaled accuracy: 0.6082698585418934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "m = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "\n",
    "m.fit(X_train_LS, y_train_LS)\n",
    "y_predicted = m.predict(X_train_TS)\n",
    "print(\"Scaled accuracy: \" + str(accuracy_score(y_train_TS, y_predicted)))\n",
    "\n",
    "m.fit(X_train_unscale[:i4], y_train[:i4])\n",
    "y_predicted = m.predict(X_train_unscale[i4:])\n",
    "print(\"Unscaled accuracy: \" + str(accuracy_score(y_train[i4:], y_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out: 0.7828571428571428\n",
      "1 out: 0.7122507122507122\n",
      "2 out: 0.865934065934066\n",
      "3 out: 0.5428109854604201\n",
      "4 out: 0.809575625680087\n",
      "Mean score: 0.7426857064364857\n",
      "Std Dev score: 0.11149381747496795\n",
      "4: 0.7426857064364857\n",
      "0 out: 0.8228571428571428\n",
      "1 out: 0.792022792022792\n",
      "2 out: 0.889010989010989\n",
      "3 out: 0.5848142164781907\n",
      "4 out: 0.8465723612622416\n",
      "Mean score: 0.7870555003262713\n",
      "Std Dev score: 0.10596711461188114\n",
      "5: 0.7870555003262713\n",
      "0 out: 0.8857142857142857\n",
      "1 out: 0.7977207977207977\n",
      "2 out: 0.8989010989010989\n",
      "3 out: 0.6187399030694669\n",
      "4 out: 0.8813928182807399\n",
      "Mean score: 0.8164937807372779\n",
      "Std Dev score: 0.10512216749504881\n",
      "6: 0.8164937807372779\n",
      "0 out: 0.9114285714285715\n",
      "1 out: 0.7991452991452992\n",
      "2 out: 0.9087912087912088\n",
      "3 out: 0.6235864297253635\n",
      "4 out: 0.8879216539717084\n",
      "Mean score: 0.8261746326124303\n",
      "Std Dev score: 0.10925107981764036\n",
      "7: 0.8261746326124303\n",
      "0 out: 0.8914285714285715\n",
      "1 out: 0.7578347578347578\n",
      "2 out: 0.9131868131868132\n",
      "3 out: 0.6381260096930533\n",
      "4 out: 0.9096844396082698\n",
      "Mean score: 0.8220521183502931\n",
      "Std Dev score: 0.1083980916908655\n",
      "8: 0.8220521183502931\n",
      "0 out: 0.9\n",
      "1 out: 0.7065527065527065\n",
      "2 out: 0.921978021978022\n",
      "3 out: 0.6365105008077544\n",
      "4 out: 0.9129488574537541\n",
      "Mean score: 0.8155980173584474\n",
      "Std Dev score: 0.11990062928689157\n",
      "9: 0.8155980173584474\n",
      "0 out: 0.9114285714285715\n",
      "1 out: 0.698005698005698\n",
      "2 out: 0.9274725274725275\n",
      "3 out: 0.6348949919224556\n",
      "4 out: 0.9162132752992383\n",
      "Mean score: 0.8176030128256981\n",
      "Std Dev score: 0.125127349668652\n",
      "10: 0.8176030128256981\n",
      "0 out: 0.9171428571428571\n",
      "1 out: 0.7037037037037037\n",
      "2 out: 0.9296703296703297\n",
      "3 out: 0.6074313408723748\n",
      "4 out: 0.9151251360174102\n",
      "Mean score: 0.8146146734813351\n",
      "Std Dev score: 0.13347536257541795\n",
      "11: 0.8146146734813351\n",
      "0 out: 0.8942857142857142\n",
      "1 out: 0.6823361823361823\n",
      "2 out: 0.9318681318681319\n",
      "3 out: 0.6397415185783522\n",
      "4 out: 0.9227421109902068\n",
      "Mean score: 0.8141947316117175\n",
      "Std Dev score: 0.12638411985549758\n",
      "12: 0.8141947316117175\n",
      "0 out: 0.9228571428571428\n",
      "1 out: 0.6652421652421653\n",
      "2 out: 0.9296703296703297\n",
      "3 out: 0.6413570274636511\n",
      "4 out: 0.9205658324265505\n",
      "Mean score: 0.8159384995319678\n",
      "Std Dev score: 0.13304245925543876\n",
      "13: 0.8159384995319678\n",
      "0 out: 0.9228571428571428\n",
      "1 out: 0.6908831908831908\n",
      "2 out: 0.9307692307692308\n",
      "3 out: 0.6429725363489499\n",
      "4 out: 0.9216539717083787\n",
      "Mean score: 0.8218272145133785\n",
      "Std Dev score: 0.12741752156188768\n",
      "14: 0.8218272145133785\n",
      "7\n",
      "0.8261746326124303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "best_depth = 0\n",
    "best_score = 0\n",
    "\n",
    "for depth in range(4, 15):\n",
    "    m = RandomForestClassifier(n_estimators=500, max_depth=depth, random_state=1, n_jobs=-1)\n",
    "    m.fit(X_train_LS, y_train_LS)\n",
    "    s = loo_cv(m, X_trains_power, y_trains)\n",
    "    print(str(depth) + ': ' + str(s))\n",
    "    if s > best_score:\n",
    "        best_depth = depth\n",
    "        best_score = s\n",
    "print(best_depth)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99: 0.8715995647442872\n",
      "99\n",
      "0.8715995647442872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# We tried a lot of MLP with different number of hidden layers and with differents number of neurons in each of the hidden layers\n",
    "# We did not implement the cross validation immediately but we used it afterwards\n",
    "best_i = 0\n",
    "best_score = 0\n",
    "\n",
    "for i in range(20, 100):\n",
    "    m = MLPClassifier(random_state=1, max_iter=500, hidden_layer_sizes=(32, i))\n",
    "    m.fit(X_train_LS, y_train_LS)\n",
    "    y_predicted = m.predict(X_train_TS)\n",
    "    score = accuracy_score(y_train_TS, y_predicted)\n",
    "    print(str(i) + ': ' + str(score))\n",
    "    if score > best_score:\n",
    "        best_i = i\n",
    "        best_score = score\n",
    "\n",
    "print(best_i)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01: 0.3144722524483134\n",
      "0.02: 0.6289445048966268\n",
      "0.03: 0.7584330794341676\n",
      "0.04: 0.8313384113166485\n",
      "0.05: 0.85310119695321\n",
      "0.060000000000000005: 0.8607181719260065\n",
      "0.06999999999999999: 0.8639825897714908\n",
      "0.08: 0.8650707290533188\n",
      "0.09: 0.8705114254624592\n",
      "0.09999999999999999: 0.8726877040261154\n",
      "0.11: 0.8759521218715995\n",
      "0.12: 0.8813928182807399\n",
      "0.13: 0.8846572361262242\n",
      "0.14: 0.8857453754080522\n",
      "0.15000000000000002: 0.8879216539717084\n",
      "0.16: 0.8900979325353645\n",
      "0.17: 0.8922742110990207\n",
      "0.18000000000000002: 0.8922742110990207\n",
      "0.19: 0.8955386289445049\n",
      "0.2: 0.8988030467899891\n",
      "0.21000000000000002: 0.9009793253536452\n",
      "0.22: 0.9053318824809575\n",
      "0.23: 0.9053318824809575\n",
      "0.24000000000000002: 0.9064200217627857\n",
      "0.25: 0.9085963003264418\n",
      "0.26: 0.9096844396082698\n",
      "0.27: 0.9107725788900979\n",
      "0.28: 0.911860718171926\n",
      "0.29000000000000004: 0.911860718171926\n",
      "0.3: 0.9107725788900979\n",
      "0.31: 0.9140369967355821\n",
      "0.32: 0.9162132752992383\n",
      "0.33: 0.9173014145810664\n",
      "0.34: 0.9162132752992383\n",
      "0.35000000000000003: 0.9151251360174102\n",
      "0.36000000000000004: 0.9173014145810664\n",
      "0.37: 0.9173014145810664\n",
      "0.38: 0.9183895538628944\n",
      "0.39: 0.9183895538628944\n",
      "0.4: 0.9194776931447225\n",
      "0.41000000000000003: 0.9183895538628944\n",
      "0.42000000000000004: 0.9205658324265505\n",
      "0.43: 0.9194776931447225\n",
      "0.44: 0.9194776931447225\n",
      "0.45: 0.9205658324265505\n",
      "0.46: 0.9216539717083787\n",
      "0.47000000000000003: 0.9216539717083787\n",
      "0.48000000000000004: 0.9216539717083787\n",
      "0.49: 0.9194776931447225\n",
      "0.5: 0.9194776931447225\n",
      "0.51: 0.9194776931447225\n",
      "0.52: 0.9205658324265505\n",
      "0.53: 0.9216539717083787\n",
      "0.54: 0.9216539717083787\n",
      "0.55: 0.9216539717083787\n",
      "0.56: 0.9216539717083787\n",
      "0.5700000000000001: 0.9216539717083787\n",
      "0.5800000000000001: 0.9227421109902068\n",
      "0.59: 0.9227421109902068\n",
      "0.6: 0.9227421109902068\n",
      "0.61: 0.9227421109902068\n",
      "0.62: 0.9227421109902068\n",
      "0.63: 0.9227421109902068\n",
      "0.64: 0.9216539717083787\n",
      "0.65: 0.9216539717083787\n",
      "0.66: 0.9205658324265505\n",
      "0.67: 0.9205658324265505\n",
      "0.68: 0.9205658324265505\n",
      "0.6900000000000001: 0.9205658324265505\n",
      "0.7000000000000001: 0.9205658324265505\n",
      "0.7100000000000001: 0.9205658324265505\n",
      "0.72: 0.9194776931447225\n",
      "0.73: 0.9194776931447225\n",
      "0.74: 0.9194776931447225\n",
      "0.75: 0.9194776931447225\n",
      "0.76: 0.9194776931447225\n",
      "0.77: 0.9183895538628944\n",
      "0.78: 0.9183895538628944\n",
      "0.79: 0.9183895538628944\n",
      "0.8: 0.9183895538628944\n",
      "0.81: 0.9194776931447225\n",
      "0.8200000000000001: 0.9194776931447225\n",
      "0.8300000000000001: 0.9183895538628944\n",
      "0.8400000000000001: 0.9183895538628944\n",
      "0.85: 0.9183895538628944\n",
      "0.86: 0.9183895538628944\n",
      "0.87: 0.9194776931447225\n",
      "0.88: 0.9194776931447225\n",
      "0.89: 0.9194776931447225\n",
      "0.9: 0.9205658324265505\n",
      "0.91: 0.9227421109902068\n",
      "0.92: 0.9227421109902068\n",
      "0.93: 0.9227421109902068\n",
      "0.9400000000000001: 0.9227421109902068\n",
      "0.9500000000000001: 0.9238302502720348\n",
      "0.9600000000000001: 0.9227421109902068\n",
      "0.97: 0.9216539717083787\n",
      "0.98: 0.9205658324265505\n",
      "0.99: 0.9194776931447225\n",
      "0.9500000000000001\n",
      "0.9238302502720348\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Same comments as MLP\n",
    "best_i = 0\n",
    "best_score = 0\n",
    "\n",
    "for i in np.arange(0.01, 1, 0.01):\n",
    "    m = svm.SVC(C=i, decision_function_shape='ovr', random_state=1)\n",
    "    m.fit(X_train_LS, y_train_LS)\n",
    "    y_predicted = m.predict(X_train_TS)\n",
    "    score = accuracy_score(y_train_TS, y_predicted)\n",
    "    print(str(i) + ': ' + str(score))\n",
    "    if score > best_score:\n",
    "        best_i = i\n",
    "        best_score = score\n",
    "\n",
    "print(best_i)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out: 0.9628571428571429\n",
      "1 out: 0.7749287749287749\n",
      "2 out: 0.932967032967033\n",
      "3 out: 0.8481421647819063\n",
      "4 out: 0.9183895538628944\n",
      "Mean score: 0.8874569338795503\n",
      "Std Dev score: 0.06770734854933125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8874569338795503"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = svm.SVC(C=0.95, decision_function_shape='ovr', random_state=1)\n",
    "loo_cv(m, X_trains_power, y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: 0.34929270946681173\n",
      "5: 0.4548422198041349\n",
      "6: 0.661588683351469\n",
      "7: 0.6974972796517954\n",
      "8: 0.5712731229597389\n",
      "9: 0.4820457018498368\n",
      "10: 0.5321001088139282\n",
      "7\n",
      "0.6974972796517954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Same comments as MLP\n",
    "best_i = 0\n",
    "best_score = 0\n",
    "\n",
    "for depth in range(4, 11):\n",
    "    m = DecisionTreeClassifier(max_depth=depth, random_state=1)\n",
    "    m.fit(X_train_LS, y_train_LS)\n",
    "    y_predicted = m.predict(X_train_TS)\n",
    "    score = accuracy_score(y_train_TS, y_predicted)\n",
    "    print(str(depth) + ': ' + str(score))\n",
    "    if score > best_score:\n",
    "        best_i = depth\n",
    "        best_score = score\n",
    "\n",
    "print(best_i)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.9042437431991295\n",
      "2: 0.8944504896626768\n",
      "3: 0.8988030467899891\n",
      "4: 0.8900979325353645\n",
      "5: 0.8900979325353645\n",
      "6: 0.8868335146898803\n",
      "7: 0.8955386289445049\n",
      "8: 0.8933623503808488\n",
      "9: 0.8966267682263329\n",
      "10: 0.8966267682263329\n",
      "11: 0.8944504896626768\n",
      "12: 0.8911860718171926\n",
      "13: 0.8944504896626768\n",
      "14: 0.8944504896626768\n",
      "15: 0.8922742110990207\n",
      "16: 0.8933623503808488\n",
      "17: 0.8933623503808488\n",
      "18: 0.8944504896626768\n",
      "19: 0.8922742110990207\n",
      "10\n",
      "0.9042437431991295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Same comments as MLP\n",
    "best_knn = 0\n",
    "best_score = 0\n",
    "\n",
    "for knn in range(1, 20):\n",
    "    m = KNeighborsClassifier(n_neighbors=knn, n_jobs=-1)\n",
    "    m.fit(X_train_LS, y_train_LS)\n",
    "    y_predicted = m.predict(X_train_TS)\n",
    "    score = accuracy_score(y_train_TS, y_predicted)\n",
    "    print(str(knn) + ': ' + str(score))\n",
    "    if score > best_score:\n",
    "        best_knn = depth\n",
    "        best_score = score\n",
    "\n",
    "print(best_knn)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out: 0.8171428571428572\n",
      "1 out: 0.6923076923076923\n",
      "2 out: 0.9076923076923077\n",
      "3 out: 0.8594507269789984\n",
      "4 out: 0.8966267682263329\n",
      "Mean score: 0.8346440704696377\n",
      "Std Dev score: 0.07792202128523171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8346440704696377"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = KNeighborsClassifier(n_neighbors=10, n_jobs=-1)\n",
    "loo_cv(m, X_trains_power, y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "m = SVC(C=1, random_state=1, shrinking=False, kernel='rbf', gamma='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out: 0.9057142857142857\n",
      "1 out: 0.8048433048433048\n",
      "2 out: 0.9120879120879121\n",
      "3 out: 0.6381260096930533\n",
      "4 out: 0.8933623503808488\n",
      "Mean score: 0.8308267725438808\n",
      "Std Dev score: 0.10385656986564047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8308267725438808"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "m1 = RandomForestClassifier(n_estimators=125, max_depth=7, random_state=1)\n",
    "m = BaggingClassifier(n_estimators=20, base_estimator=m1)\n",
    "# Leave-One-Out Cross-Validation\n",
    "loo_cv(m, X_trains_power, y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out: 0.9457142857142857\n",
      "1 out: 0.8034188034188035\n",
      "2 out: 0.9252747252747253\n",
      "3 out: 0.8691437802907916\n",
      "4 out: 0.9434167573449401\n",
      "Mean score: 0.8973936704087093\n",
      "Std Dev score: 0.05451548685013476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8973936704087093"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# These models are scored using the cross validation. We call the function below.\n",
    "\n",
    "m1 = RandomForestClassifier(n_estimators=500, max_depth=7, random_state=1, n_jobs=-1)\n",
    "m2 = MLPClassifier(random_state=1, max_iter=500, hidden_layer_sizes=(132,40))\n",
    "m3 = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "m = VotingClassifier(estimators=[('rf', m1), ('mlp', m2), ('knn,', m3)], weights=[2,3,2], voting='hard')\n",
    "loo_cv(m, X_trains_power, y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters optimization to find accurate parameters, this is long to run...\n",
    "depth_values = [5, 6, 7]\n",
    "layer_sizes = [((100, 30), (120, 40), (130, 40), (135, 50), (150, 40), (170, 70) ,(130, 50, 50))]\n",
    "n_neighbors = [3, 4, 5, 6, 7, 8]\n",
    "\n",
    "best_score = 0\n",
    "best_depth = None\n",
    "best_neighbors = None\n",
    "best_layer = None\n",
    "\n",
    "for depth in depth_values:\n",
    "    for knn in n_neighbors:\n",
    "        for layer_size in layer_sizes:\n",
    "            print(\"################################\")\n",
    "            print(\"depth=\" + str(depth) + \" \\nknn=\" + str(knn) + \" \\nlayer_size=\" + str(layer_size))\n",
    "            m1 = RandomForestClassifier(max_depth=depth, random_state=1)\n",
    "            m2 = MLPClassifier(random_state=1, max_iter=500, hidden_layer_sizes=layer_size)\n",
    "            m3 = KNeighborsClassifier(n_neighbors=knn)\n",
    "            m = VotingClassifier(estimators=[('rf', m1), ('mlp', m2), ('knn,', m3)], weights=[3,3,2], voting='hard')\n",
    "            s = loo_cv(m)\n",
    "            if s > best_score:\n",
    "                best_score = s\n",
    "                best_depth = depth\n",
    "                best_neighbors = knn\n",
    "                best_layer = layer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9012510437194289\n",
      "7\n",
      "3\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "print(best_score)\n",
    "print(best_depth) \n",
    "print(best_neighbors)\n",
    "print(best_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(X_train, y_train)\n",
    "y_test = m.predict(X_test_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission eclf_3_fourier_iqr_layer_132_40_knn3_no_outliers.csv saved in submissions\\eclf_3_fourier_iqr_layer_132_40_knn3_no_outliers.csv.\n"
     ]
    }
   ],
   "source": [
    "def write_submission(y, where, submission_name='eclf_3_fourier_iqr_layer_132_40_knn3_no_outliers.csv'):\n",
    "\n",
    "    os.makedirs(where, exist_ok=True)\n",
    "\n",
    "    SUBMISSION_PATH = os.path.join(where, submission_name)\n",
    "    if os.path.exists(SUBMISSION_PATH):\n",
    "        os.remove(SUBMISSION_PATH)\n",
    "\n",
    "    y = y.astype(int)\n",
    "    outputs = np.unique(y)\n",
    "\n",
    "    # Verify conditions on the predictions\n",
    "    if np.max(outputs) > 14:\n",
    "        raise ValueError('Class {} does not exist.'.format(np.max(outputs)))\n",
    "    if np.min(outputs) < 1:\n",
    "        raise ValueError('Class {} does not exist.'.format(np.min(outputs)))\n",
    "    \n",
    "    # Write submission file\n",
    "    with open(SUBMISSION_PATH, 'a') as file:\n",
    "        n_samples = len(y)\n",
    "        if n_samples != 3500:\n",
    "            raise ValueError('Check the number of predicted values.')\n",
    "\n",
    "        file.write('Id,Prediction\\n')\n",
    "\n",
    "        for n, i in enumerate(y):\n",
    "            file.write('{},{}\\n'.format(n+1, int(i)))\n",
    "\n",
    "    print('Submission {} saved in {}.'.format(submission_name, SUBMISSION_PATH))\n",
    "\n",
    "write_submission(y_test, 'submissions')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "565f6772ba1fecb568f7d4614a6019a79b3d2b0fdb8dbbb76cc8986309b24fae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
